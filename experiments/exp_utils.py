"""
Utility functions for experiments.
"""
from typing import Tuple, List
import time
import numpy as np
import tensorflow as tf
from gpflow.likelihoods import Bernoulli
import gpflow
from gpflow.models.svgp import SVGP
import hydra

import sys

sys.path.append("../..")

from src.models.tsvgp_white import t_SVGP_white
from src.models.tsvgp_cont import OnlineGP
from src.models.tsvgp import base_SVGP


def get_hydra_output_dir():
    """Return the current output directory path generated by hydra"""
    hydra_cfg = hydra.core.hydra_config.HydraConfig.get()
    return hydra_cfg['runtime']['output_dir']


def optimize_full_model(model, train_data: [np.ndarray, np.ndarray],
                        test_data: [np.ndarray, np.ndarray], optimizer: tf.optimizers,
                        minibatch_size: int = 64,
                        iterations: int = 100, debug: bool = False,
                        lambda_lr: float = 0.5) -> [list, list]:
    """
    Optimize t-SVGP (white) model using minibatches and return the ELBO and NLPD values.
    """

    if not (isinstance(model, t_SVGP_white) or isinstance(model, SVGP)):
        raise Exception("Model not supported for optimization!")

    n_train = train_data[0].shape[0]
    if n_train < 50000:
        train_dataset = tf.data.Dataset.from_tensor_slices(train_data).repeat().shuffle(n_train)
    else:
        train_dataset = tf.data.Dataset.from_tensor_slices(train_data).repeat()

    train_iter = iter(train_dataset.batch(minibatch_size))

    training_loss = model.training_loss_closure(train_iter, compile=True)

    @tf.function
    def optimization_step():
        optimizer.minimize(training_loss, model.trainable_variables)
        if isinstance(model, t_SVGP_white):
            model.natgrad_step(train_data, lr=lambda_lr)

    elbo_vals = []
    nlpd_vals = []
    eval_metric = []
    for step in range(iterations):
        optimization_step()
        elbo_vals.append(-training_loss().numpy())
        nlpd_vals.append(get_predictive_nlpd(model, test_data))

        if isinstance(model.likelihood, Bernoulli):
            eval_metric.append(get_accuracy(model, test_data))
        elif isinstance(model.likelihood, gpflow.likelihoods.Softmax):
            pred_m, _ = model.predict_y(test_data[0])
            pred_argmax = tf.reshape(tf.argmax(pred_m, axis=1), (-1, 1))
            acc = np.mean(pred_argmax == test_data[1])
            eval_metric.append(acc)
        else:
            eval_metric.append(get_rmse(model, test_data))

        if debug and step % 20 == 0:
            print(f"{step} Iteration; NLPD {nlpd_vals[-1]}; Evaluation metric (RMSE/Acc.) {eval_metric[-1]}")

    return elbo_vals, nlpd_vals, eval_metric


def get_predictive_nlpd(model: base_SVGP, test_data: Tuple[np.ndarray, np.ndarray]) -> float:
    """
    Calculate and return negative log predictive density (NLPD).
    """
    return -1 * tf.reduce_mean(model.predict_log_density(test_data))


def get_accuracy(model: base_SVGP, test_data: Tuple[np.ndarray, np.ndarray]) -> float:
    """
    Calculate and returns accuracy in classification case.
    """
    pred_mean, _ = model.predict_y(test_data[0])
    pred_mean = pred_mean.numpy()
    pred_mean[pred_mean >= 0.5] = 1
    pred_mean[pred_mean < 0.5] = 0
    correct_prediction = np.sum(pred_mean == test_data[1])
    return correct_prediction / test_data[0].shape[0]


def get_rmse(model: base_SVGP, test_data: Tuple[np.ndarray, np.ndarray]):
    """
    Calculates RMSE.
    """
    y_pred, _ = model.predict_y(test_data[0])
    return np.sqrt(np.mean(np.square(y_pred - test_data[1])))


def get_multiclass_accuracy(model: base_SVGP, test_data: Tuple[np.ndarray, np.ndarray]) -> float:
    """
    Get multiclass accuracy
    """
    pred_m, _ = model.predict_y(test_data[0])
    pred_argmax = tf.reshape(tf.argmax(pred_m, axis=1), (-1, 1))
    acc = np.mean(pred_argmax == test_data[1]).item()
    return acc


def convert_data_to_online(data: [np.ndarray, np.ndarray], n_sets: int,
                           shuffle: bool = True, sort_data: bool = False) -> list:
    """
    Get an offline data and convert it into an online dataset of n_sets.

    returns: a list of tuple of np.ndarray (X_i, Y_i) with X_i of shape [n_set_data, data_dim] and
             Y is of shape [n_set_data, output_dim].
    """
    Y_dtype = data[1].dtype

    X, Y = data
    XY = np.concatenate([X, Y], axis=1)

    if shuffle:
        np.random.shuffle(XY)

    if sort_data:
        np.sort(XY, axis=0)

    n = XY.shape[0]
    last_set_size = int(n % n_sets)
    set_size = int((n - last_set_size) / n_sets - 1)

    streaming_data = []
    for i in range(n_sets - 1):
        set_data = XY[i * set_size: (i + 1) * set_size]
        Y_casted = set_data[:, X.shape[-1]:].astype(Y_dtype)
        streaming_data.append((set_data[:, :X.shape[-1]], Y_casted))

    # Adding last set; this could be more than other sets as well
    set_data = XY[(n_sets - 1) * set_size:]

    Y_casted = set_data[:, X.shape[-1]:].astype(Y_dtype)
    streaming_data.append((set_data[:, :X.shape[-1]], Y_casted))

    assert len(streaming_data) == n_sets
    assert streaming_data[0][0].shape[-1] == X.shape[-1]
    assert streaming_data[0][1].shape[-1] == Y.shape[-1]

    return streaming_data


def optimize_online_model(online_gp: OnlineGP, train_data: List[Tuple[np.ndarray, np.ndarray]],
                          test_data: Tuple[np.ndarray, np.ndarray], train_hyperparams: bool = False,
                          hyperparams_step: int = 10, train_memory: bool = False, debug: bool = False) -> [list, list,
                                                                                                           list]:
    """
    Optimize online GP model on train data, which are already in streaming set, and returns nlpd values on test set,
    rmse or accuracy value, and time taken.
    """
    n_sets = len(train_data)

    if debug:
        print(f"Initial NLPD: {get_predictive_nlpd(online_gp.model, test_data)}")

    nlpd_vals = []
    eval_metric = []
    time_vals = []
    for n in range(n_sets):
        for var in online_gp.optimizer.variables():
            var.assign(tf.zeros_like(var))

        start_time = time.time()
        new_data = train_data[n]
        new_data = (new_data[0], new_data[1])
        online_gp.update_with_new_batch(new_data, n_hyp_opt_steps=hyperparams_step, train_hyps=train_hyperparams,
                                        train_mem=train_memory, remove_memory=True, return_kernel_params=False)

        time_vals.append(time.time() - start_time)

        nlpd_vals.append(get_predictive_nlpd(online_gp.model, test_data))

        if isinstance(online_gp.model.likelihood, Bernoulli):
            eval_metric.append(get_accuracy(online_gp.model, test_data))
        elif isinstance(online_gp.model.likelihood, gpflow.likelihoods.Softmax):
            eval_metric.append(get_multiclass_accuracy(online_gp.model, test_data))
        else:
            eval_metric.append(get_rmse(online_gp.model, test_data))

        if debug:
            print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")
            print(f"Set {n}")
            print(f"NLPD = {nlpd_vals[-1]}")
            print(f"Eval. metric (RMSE/Acc.) = {eval_metric[-1]}")
            print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")

    return nlpd_vals, eval_metric, time_vals
